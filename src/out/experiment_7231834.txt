/home/xinyuzhao/faultModel/src
SLURM task ID: 
what1
what2
what3
no change     /home/xinyuzhao/miniconda3/condabin/conda
no change     /home/xinyuzhao/miniconda3/bin/conda
no change     /home/xinyuzhao/miniconda3/bin/conda-env
no change     /home/xinyuzhao/miniconda3/bin/activate
no change     /home/xinyuzhao/miniconda3/bin/deactivate
no change     /home/xinyuzhao/miniconda3/etc/profile.d/conda.sh
no change     /home/xinyuzhao/miniconda3/etc/fish/conf.d/conda.fish
no change     /home/xinyuzhao/miniconda3/shell/condabin/Conda.psm1
no change     /home/xinyuzhao/miniconda3/shell/condabin/conda-hook.ps1
no change     /home/xinyuzhao/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh
no change     /home/xinyuzhao/miniconda3/etc/profile.d/conda.csh
no change     /home/xinyuzhao/.bashrc
No action taken.
True
Files already downloaded and verified
Files already downloaded and verified
ResNet18(
  (resnet): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=10, bias=True)
  )
)
Trainable parameters: 11181642
Train Epoch: 1 [0/45000 (0%)] Loss: 2.609106
Train Epoch: 1 [1408/45000 (3%)] Loss: 0.792252
Train Epoch: 1 [2816/45000 (6%)] Loss: 0.860884
Train Epoch: 1 [4224/45000 (9%)] Loss: 0.683685
Train Epoch: 1 [5632/45000 (13%)] Loss: 0.595203
Train Epoch: 1 [7040/45000 (16%)] Loss: 0.514091
Train Epoch: 1 [8448/45000 (19%)] Loss: 0.689370
Train Epoch: 1 [9856/45000 (22%)] Loss: 0.594613
Train Epoch: 1 [11264/45000 (25%)] Loss: 0.477497
Train Epoch: 1 [12672/45000 (28%)] Loss: 0.551077
Train Epoch: 1 [14080/45000 (31%)] Loss: 0.468372
Train Epoch: 1 [15488/45000 (34%)] Loss: 0.446397
Train Epoch: 1 [16896/45000 (38%)] Loss: 0.549604
Train Epoch: 1 [18304/45000 (41%)] Loss: 0.416769
Train Epoch: 1 [19712/45000 (44%)] Loss: 0.533015
Train Epoch: 1 [21120/45000 (47%)] Loss: 0.454674
Train Epoch: 1 [22528/45000 (50%)] Loss: 0.574237
Train Epoch: 1 [23936/45000 (53%)] Loss: 0.482164
Train Epoch: 1 [25344/45000 (56%)] Loss: 0.298016
Train Epoch: 1 [26752/45000 (59%)] Loss: 0.389125
Train Epoch: 1 [28160/45000 (63%)] Loss: 0.525287
Train Epoch: 1 [29568/45000 (66%)] Loss: 0.390284
Train Epoch: 1 [30976/45000 (69%)] Loss: 0.400350
Train Epoch: 1 [32384/45000 (72%)] Loss: 0.494591
Train Epoch: 1 [33792/45000 (75%)] Loss: 0.469846
Train Epoch: 1 [35200/45000 (78%)] Loss: 0.517540
Train Epoch: 1 [36608/45000 (81%)] Loss: 0.435908
Train Epoch: 1 [38016/45000 (84%)] Loss: 0.447393
Train Epoch: 1 [39424/45000 (88%)] Loss: 0.554137
Train Epoch: 1 [40832/45000 (91%)] Loss: 0.404984
Train Epoch: 1 [42240/45000 (94%)] Loss: 0.239016
Train Epoch: 1 [43648/45000 (97%)] Loss: 0.391754
    epoch          : 1
    loss           : 0.5258808452212675
    accuracy       : 0.8199376578282828
    top_k_acc      : 0.9621951941287878
    val_loss       : 0.4494905234137668
    val_accuracy   : 0.8512658227848101
    val_top_k_acc  : 0.974189082278481
Saving checkpoint: saved/models/CIFAR_10_ResNet_18_BASE/0110_140934/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
START Weight Fault inject
