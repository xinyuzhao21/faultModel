/home/xinyuzhao/faultModel/src
SLURM task ID: 
what1
what2
what3
no change     /home/xinyuzhao/miniconda3/condabin/conda
no change     /home/xinyuzhao/miniconda3/bin/conda
no change     /home/xinyuzhao/miniconda3/bin/conda-env
no change     /home/xinyuzhao/miniconda3/bin/activate
no change     /home/xinyuzhao/miniconda3/bin/deactivate
no change     /home/xinyuzhao/miniconda3/etc/profile.d/conda.sh
no change     /home/xinyuzhao/miniconda3/etc/fish/conf.d/conda.fish
no change     /home/xinyuzhao/miniconda3/shell/condabin/Conda.psm1
no change     /home/xinyuzhao/miniconda3/shell/condabin/conda-hook.ps1
no change     /home/xinyuzhao/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh
no change     /home/xinyuzhao/miniconda3/etc/profile.d/conda.csh
no change     /home/xinyuzhao/.bashrc
No action taken.
True
Files already downloaded and verified
Training Size: (50000, 32, 32, 3)
Files already downloaded and verified
Validation Size: (10000, 32, 32, 3)
ResNet18(
  (resnet): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=10, bias=True)
  )
)
Trainable parameters: 11181642
Train Epoch: 1 [0/50000 (0%)] Loss: 2.565057
Train Epoch: 1 [1408/50000 (3%)] Loss: 1.124067
Train Epoch: 1 [2816/50000 (6%)] Loss: 0.729107
Train Epoch: 1 [4224/50000 (8%)] Loss: 0.770358
Train Epoch: 1 [5632/50000 (11%)] Loss: 0.646670
Train Epoch: 1 [7040/50000 (14%)] Loss: 0.686757
Train Epoch: 1 [8448/50000 (17%)] Loss: 0.504007
Train Epoch: 1 [9856/50000 (20%)] Loss: 0.596895
Train Epoch: 1 [11264/50000 (23%)] Loss: 0.515186
Train Epoch: 1 [12672/50000 (25%)] Loss: 0.541436
Train Epoch: 1 [14080/50000 (28%)] Loss: 0.452568
Train Epoch: 1 [15488/50000 (31%)] Loss: 0.421326
Train Epoch: 1 [16896/50000 (34%)] Loss: 0.466160
Train Epoch: 1 [18304/50000 (37%)] Loss: 0.452958
Train Epoch: 1 [19712/50000 (39%)] Loss: 0.389099
Train Epoch: 1 [21120/50000 (42%)] Loss: 0.553928
Train Epoch: 1 [22528/50000 (45%)] Loss: 0.628692
Train Epoch: 1 [23936/50000 (48%)] Loss: 0.517956
Train Epoch: 1 [25344/50000 (51%)] Loss: 0.463135
Train Epoch: 1 [26752/50000 (54%)] Loss: 0.473593
Train Epoch: 1 [28160/50000 (56%)] Loss: 0.486000
Train Epoch: 1 [29568/50000 (59%)] Loss: 0.542502
Train Epoch: 1 [30976/50000 (62%)] Loss: 0.466672
Train Epoch: 1 [32384/50000 (65%)] Loss: 0.322425
Train Epoch: 1 [33792/50000 (68%)] Loss: 0.304985
Train Epoch: 1 [35200/50000 (70%)] Loss: 0.376594
Train Epoch: 1 [36608/50000 (73%)] Loss: 0.384447
Train Epoch: 1 [38016/50000 (76%)] Loss: 0.454239
Train Epoch: 1 [39424/50000 (79%)] Loss: 0.319793
Train Epoch: 1 [40832/50000 (82%)] Loss: 0.315122
Train Epoch: 1 [42240/50000 (84%)] Loss: 0.300512
Train Epoch: 1 [43648/50000 (87%)] Loss: 0.399239
Train Epoch: 1 [45056/50000 (90%)] Loss: 0.416914
Train Epoch: 1 [46464/50000 (93%)] Loss: 0.435509
Train Epoch: 1 [47872/50000 (96%)] Loss: 0.289804
Train Epoch: 1 [49280/50000 (99%)] Loss: 0.490182
Actual Validation size (10000, 32, 32, 3)
    epoch          : 1
    loss           : 0.4937865190265124
    accuracy       : 0.8308224104859335
    top_k_acc      : 0.9663762787723784
    val_loss       : 0.434389043835145
    val_accuracy   : 0.8592761075949367
    val_top_k_acc  : 0.9765625
Saving checkpoint: saved/models/CIFAR_10_ResNet_18_BASE/0110_143332/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
START Weight Fault inject
